{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import xlrd\n",
    "import xlwt\n",
    "import csv\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/Users/maheshreddy/Documents/GitHub Destop/PHBS_ML_Project/Housing_Pricing/Data/train.csv')\n",
    "test_df = pd.read_csv('/Users/maheshreddy/Documents/GitHub Destop/PHBS_ML_Project/Housing_Pricing/Data/test.csv')\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we test various models with the parameters we consider important in the prediction of SalePrice. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running a basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_df.SalePrice\n",
    "predictor_cols = ['LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'TotRmsAbvGrd']\n",
    "train_X = train_df[predictor_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.849999999999994"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier()\n",
    "random_forest.fit(train_X, train_y)\n",
    "random_forest.score(train_X, train_y)\n",
    "acc_random_forest = round(random_forest.score(train_X, train_y) * 100, 2)\n",
    "acc_random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[121500 137500 159000 ..., 157900  93500 260000]\n"
     ]
    }
   ],
   "source": [
    "test_X = test_df[predictor_cols]\n",
    "predicted_prices = random_forest.predict(test_X)\n",
    "print(predicted_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.769999999999996"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(train_X, train_y)\n",
    "acc_decision_tree = round(decision_tree.score(train_X, train_y) * 100, 2)\n",
    "acc_decision_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[137000 230000 159000 ..., 228950 145000 260000]\n"
     ]
    }
   ],
   "source": [
    "test_X = test_df[predictor_cols]\n",
    "predicted_prices = decision_tree.predict(test_X)\n",
    "print(predicted_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_mae(max_leaf_nodes, predictors_train, predictors_val, targ_train, targ_val):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n",
    "    model.fit(predictors_train, targ_train)\n",
    "    preds_val = model.predict(predictors_val)\n",
    "    mae = mean_absolute_error(targ_val, preds_val)\n",
    "    return(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max leaf nodes: 5  \t\t Mean Absolute Error:  32224\n",
      "Max leaf nodes: 10  \t\t Mean Absolute Error:  31230\n",
      "Max leaf nodes: 20  \t\t Mean Absolute Error:  30037\n",
      "Max leaf nodes: 30  \t\t Mean Absolute Error:  29257\n",
      "Max leaf nodes: 40  \t\t Mean Absolute Error:  28881\n",
      "Max leaf nodes: 46  \t\t Mean Absolute Error:  27975\n",
      "Max leaf nodes: 47  \t\t Mean Absolute Error:  28083\n",
      "Max leaf nodes: 48  \t\t Mean Absolute Error:  28087\n",
      "Max leaf nodes: 49  \t\t Mean Absolute Error:  27919\n",
      "Max leaf nodes: 50  \t\t Mean Absolute Error:  27796\n",
      "Max leaf nodes: 51  \t\t Mean Absolute Error:  27895\n",
      "Max leaf nodes: 52  \t\t Mean Absolute Error:  28188\n",
      "Max leaf nodes: 53  \t\t Mean Absolute Error:  28137\n",
      "Max leaf nodes: 54  \t\t Mean Absolute Error:  28129\n",
      "Max leaf nodes: 55  \t\t Mean Absolute Error:  28161\n",
      "Max leaf nodes: 60  \t\t Mean Absolute Error:  28543\n",
      "Max leaf nodes: 70  \t\t Mean Absolute Error:  28396\n",
      "Max leaf nodes: 80  \t\t Mean Absolute Error:  27921\n",
      "Max leaf nodes: 90  \t\t Mean Absolute Error:  28026\n",
      "Max leaf nodes: 100  \t\t Mean Absolute Error:  28513\n",
      "Max leaf nodes: 500  \t\t Mean Absolute Error:  30147\n",
      "Max leaf nodes: 1000  \t\t Mean Absolute Error:  30597\n",
      "Max leaf nodes: 5000  \t\t Mean Absolute Error:  30596\n"
     ]
    }
   ],
   "source": [
    "# split data into training and validation data, for both predictors and target\n",
    "train_X1, val_X1, train_y1, val_y1 = train_test_split(train_X, train_y,random_state = 0)\n",
    "\n",
    "# compare MAE with differing values of max_leaf_nodes\n",
    "for max_leaf_nodes in [5, 10, 20, 30, 40, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 60, 70, 80, 90, 100, 500, 1000, 5000]:\n",
    "    my_mae = get_mae(max_leaf_nodes, train_X1, val_X1, train_y1, val_y1)\n",
    "    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(max_leaf_nodes, my_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We have noted that the MAE is the least at max_leaf_nodes = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.790000000000006"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gradient Boost\n",
    "\n",
    "gb_model = GradientBoostingRegressor()\n",
    "gb_model.fit(train_X,train_y)\n",
    "acc_gb_model = round(gb_model.score(train_X, train_y) * 100, 2)\n",
    "acc_gb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 140683.14330348  176510.8237457   163904.56918469 ...,  183644.09805252\n",
      "  154933.1337181   245528.76008422]\n"
     ]
    }
   ],
   "source": [
    "gb_pred_prices = gb_model.predict(test_X)\n",
    "print(gb_pred_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost with parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.159999999999997"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gradient Boost with parameters\n",
    "\n",
    "gb_plus_model = GradientBoostingRegressor(n_estimators=10000, learning_rate=0.01)\n",
    "gb_plus_model.fit(train_X,train_y)\n",
    "acc_gb_plus_model = round(gb_plus_model.score(train_X, train_y) * 100, 2)\n",
    "acc_gb_plus_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 141886.16800252  152280.38145345  152511.51439765 ...,  169101.12274727\n",
      "  166486.43543444  250096.01655477]\n"
     ]
    }
   ],
   "source": [
    "gb_plus_pred_prices = gb_plus_model.predict(test_X)\n",
    "print(gb_plus_pred_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that for our given parameters, Decision Tree Classifier is the best one amongst the ones used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
